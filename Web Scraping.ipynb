{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2020ae1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Post\n",
    "<br>\n",
    "<br>\n",
    "This notebook will conduct web-scraping in order to find the cities, districts and regions of the firms.\n",
    "<br>\n",
    "<br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b0b3764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following code comes from another notebook I used to scrape the cities/ distircts/ regions.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "import urllib3\n",
    "import config\n",
    "import time\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import urlopen as uReq\n",
    "\n",
    "# Remove request warnings\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "# define the agent for the web scraping\n",
    "agent = {\"User-Agent\":\"Mozilla/5.0\"}\n",
    "\n",
    "#df1 = pd.read_csv(r'C:\\Users\\cgirardi\\OneDrive - zeb\\Desktop\\Python Data\\Python Practice_Data Big\\DF1.csv')\n",
    "df1 = pd.read_csv('/Users/cirillogirardi/Desktop/Dissertation/code_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f37779",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The option is that of scraping the information pertinent to the postcodes (i.e. cities, regions, etc.) from German administrative websites. Once that is done, the information retrieved can be used to aid the clustering\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96978f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['pl'].fillna(0, inplace=True)\n",
    "\n",
    "df1.drop(columns=['bvr'], inplace=True)\n",
    "\n",
    "df1.dropna(inplace=True)\n",
    "\n",
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27791974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all the Postcodes to allow for scraping\n",
    "\n",
    "Posters = df1['post'].tolist()\n",
    "\n",
    "Poster = []\n",
    "\n",
    "for i in Posters:\n",
    "    g = int(i)\n",
    "    Poster.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506828f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "citiesss = []\n",
    "regionsss = []\n",
    "districttt = []\n",
    "\n",
    "# create a loop to iterate through every Postalcode in the list\n",
    "\n",
    "for i in Poster[0:]:\n",
    "    #get the link by joining the website URL and the Postcode\n",
    "    link = 'https://www.worldpostalcodes.org/l1/en/de/germany/profile/postalcode/{}'.format(i)\n",
    "    # get access using the specified criteria\n",
    "    web = requests.get(link, verify=True, headers=agent)\n",
    "    # set a sleep time between accesses\n",
    "    time.sleep(1)\n",
    "    # scrape the website using beautiful soup using an html parser\n",
    "    page_soup = soup(web.content, 'html.parser')\n",
    "    # create a wrap to locate the ZIP and the info\n",
    "    needed = page_soup.find_all('td')\n",
    "    \n",
    "    try:\n",
    "        # retreive the text of the City\n",
    "        city = needed[3].text\n",
    "        citiesss.append(city)\n",
    "    except:\n",
    "        citiesss.append('null')\n",
    "    \n",
    "    try:\n",
    "        # retreive the text of the Region\n",
    "        region = needed[5].text\n",
    "        regionsss.append(region)\n",
    "    except:\n",
    "        regionsss.append('null')\n",
    "        \n",
    "    try:\n",
    "        # retreive the text of the District\n",
    "        district = needed[7].text\n",
    "        districttt.append(district)\n",
    "    except:\n",
    "        districttt.append('null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf11c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'postcode': Poster, 'city': citiesss, 'region': regionsss, 'district': districttt}\n",
    "\n",
    "\n",
    "df_post = pd.DataFrame(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe415c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post.to_csv('postcode.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "id": "42089098",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "id": "df13686f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dortmund                       8296\n",
       "Landkreis Unna                 3942\n",
       "Hamm                           3348\n",
       "Landkreis Recklinghausen        871\n",
       "Landkreis Ennepe-Ruhr-Kreis     410\n",
       "                               ... \n",
       "Landau in der Pfalz               1\n",
       "Landkreis Altötting               1\n",
       "Wiesbaden                         1\n",
       "Landkreis Ahrweiler               1\n",
       "Landkreis Börde                   1\n",
       "Name: district, Length: 147, dtype: int64"
      ]
     },
     "execution_count": 969,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_post.district.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "a61fde86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dortmund          8296\n",
       "Hamm              3348\n",
       "Unna              1379\n",
       "Schwerte           983\n",
       "Castrop-Rauxel     685\n",
       "                  ... \n",
       "Wertach              1\n",
       "Bosau                1\n",
       "Kleve                1\n",
       "Velbert              1\n",
       "Seefeld              1\n",
       "Name: city, Length: 277, dtype: int64"
      ]
     },
     "execution_count": 970,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_post['city'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "id": "227a079d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 971,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double-check if the lengths match \n",
    "\n",
    "(len(df1) - 26) - (len(df_post))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
